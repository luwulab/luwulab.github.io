<!doctype html><html lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Luwu.AI Lab - Exploring the Frontiers of Artificial Intelligence"><title>Blog - Luwu.AI - AI Research Lab</title><link rel=stylesheet href=/css/style.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&family=Noto+Sans+SC:wght@300;400;600;700&display=swap" rel=stylesheet></head><body><header class=site-header><nav class=navbar><div class=container><div class=nav-wrapper><a href=/ class=logo><span class=logo-icon>ü¶Å</span>
<span class=logo-text>Luwu.AI</span>
</a><button class=mobile-menu-toggle aria-label="Toggle menu">
<span></span>
<span></span>
<span></span></button><ul class=nav-menu><li class=nav-item><a href=/ class=nav-link>Home</a></li><li class=nav-item><a href=/about/ class=nav-link>About</a></li><li class=nav-item><a href=/projects/ class=nav-link>Projects</a></li><li class=nav-item><a href=/blog/ class=nav-link>Blog</a></li><li class=nav-item><a href=/changelog/ class=nav-link>Changelog</a></li></ul></div></div></nav></header><main class=main-content><div class=list-page><div class=container><header class=page-header><h1 class=page-title>Blog</h1><p class=page-description>Sharing AI research insights and practical experiences</p></header><div class=list-content><div class=blog-list><article class=blog-item><div class=blog-item-meta><time datetime=2025-12-23>2025-12-23</time>
<span class=category>Deep Learning</span></div><h2><a href=https://luwu.ai/blog/transformer-explained/>Understanding the Transformer Architecture</a></h2><p class=summary><h2 id=introduction>Introduction</h2><p>Since its introduction in 2017, the Transformer architecture has become the cornerstone of natural language processing. This article provides an in-depth yet accessible explanation of Transformer&rsquo;s core mechanisms.</p><h2 id=why-do-we-need-transformers>Why Do We Need Transformers?</h2><p>Before Transformers, RNNs and LSTMs were the mainstream methods for sequence modeling. However, they had several limitations:</p><ol><li><strong>Sequential Computation</strong> - Cannot be parallelized, leading to low training efficiency</li><li><strong>Long-range Dependencies</strong> - Difficulty capturing long-distance contextual information</li><li><strong>Gradient Issues</strong> - Long sequences prone to vanishing gradients</li></ol><p>Transformers elegantly solve these problems through the <strong>self-attention mechanism</strong>.</p></p><div class=tags><span class=tag>Transformer</span>
<span class=tag>NLP</span>
<span class=tag>Attention Mechanism</span></div><a href=https://luwu.ai/blog/transformer-explained/ class=read-more>Read More ‚Üí</a></article><article class=blog-item><div class=blog-item-meta><time datetime=2025-12-20>2025-12-20</time>
<span class=category>Computer Vision</span></div><h2><a href=https://luwu.ai/blog/diffusion-models-intro/>Diffusion Models: A New Paradigm for AI Image Generation</a></h2><p class=summary><h2 id=what-are-diffusion-models>What are Diffusion Models?</h2><p>Diffusion Models are a class of powerful generative models that create high-quality images from random noise through a gradual denoising process.</p><h2 id=core-concepts>Core Concepts</h2><p>Diffusion models involve two key processes:</p><h3 id=1-forward-diffusion-process-adding-noise>1. Forward Diffusion Process (Adding Noise)</h3><p>Gradually add Gaussian noise to data until it becomes pure noise:</p><p>$$
x_t = \sqrt{\alpha_t} x_0 + \sqrt{1-\alpha_t} \epsilon
$$</p><h3 id=2-reverse-denoising-process-generation>2. Reverse Denoising Process (Generation)</h3><p>Train a neural network to learn the reverse process, recovering data from noise:</p></p><div class=tags><span class=tag>Diffusion Models</span>
<span class=tag>Generative Models</span>
<span class=tag>Image Generation</span></div><a href=https://luwu.ai/blog/diffusion-models-intro/ class=read-more>Read More ‚Üí</a></article><article class=blog-item><div class=blog-item-meta><time datetime=2025-12-18>2025-12-18</time>
<span class=category>Reinforcement Learning</span></div><h2><a href=https://luwu.ai/blog/reinforcement-learning-basics/>Introduction to Reinforcement Learning: From Zero to AlphaGo</a></h2><p class=summary><h2 id=what-is-reinforcement-learning>What is Reinforcement Learning?</h2><p>Reinforcement Learning (RL) is an important branch of machine learning that studies how agents learn optimal policies in an environment through trial and error.</p><h3 id=core-concepts>Core Concepts</h3><ul><li><strong>Agent</strong>: The subject that learns and makes decisions</li><li><strong>Environment</strong>: The world in which the agent operates</li><li><strong>State</strong>: The current situation of the environment</li><li><strong>Action</strong>: Operations the agent can perform</li><li><strong>Reward</strong>: Feedback signal from the environment about actions</li></ul><h2 id=difference-between-rl-and-supervised-learning>Difference Between RL and Supervised Learning</h2><table><thead><tr><th>Dimension</th><th>Supervised Learning</th><th>Reinforcement Learning</th></tr></thead><tbody><tr><td>Learning Method</td><td>Learn from labeled data</td><td>Learn from interactions</td></tr><tr><td>Feedback</td><td>Immediate correct answers</td><td>Delayed reward signals</td></tr><tr><td>Objective</td><td>Fit labels</td><td>Maximize cumulative rewards</td></tr><tr><td>Exploration</td><td>No exploration needed</td><td>Need to balance exploration vs exploitation</td></tr></tbody></table><h2 id=mathematical-framework-markov-decision-process>Mathematical Framework: Markov Decision Process</h2><p>RL problems are typically modeled as Markov Decision Processes (MDP):</p></p><div class=tags><span class=tag>RL</span>
<span class=tag>Deep Learning</span>
<span class=tag>Agents</span></div><a href=https://luwu.ai/blog/reinforcement-learning-basics/ class=read-more>Read More ‚Üí</a></article></div></div></div></div></main><footer class=site-footer><div class=container><div class=footer-content><div class=footer-section><h3>Luwu.AI Lab</h3><p>Exploring the Infinite Possibilities of AI</p><p class=mythology-quote>"ÈôÜÂêæËÄÖÔºåÊòÜ‰ªë‰πãÁ•û‰πü„ÄÇ‰∫∫Èù¢ËôéÁà™ÔºåËôéË∫´‰πùÂ∞æ„ÄÇ"</p></div><div class=footer-section><h4>Quick Links</h4><ul><li><a href=/>Home</a></li><li><a href=/about/>About</a></li><li><a href=/projects/>Projects</a></li><li><a href=/blog/>Blog</a></li><li><a href=/changelog/>Changelog</a></li></ul></div><div class=footer-section><h4>Contact Us</h4><ul class=social-links><li><a href=https://github.com/luwulab target=_blank>GitHub</a></li><li><a href=mailto:support@luwu.ai>Email</a></li></ul></div></div><div class=footer-bottom><p>&copy; 2025 Luwu.AI Lab. All rights reserved.</p></div></div></footer><script src=/js/main.js></script></body></html>